{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install roboflow\n!pip install supervision","metadata":{"_uuid":"c1c538f2-4af1-4332-aaf1-4f864285b1d0","_cell_guid":"17bdaafc-b0c8-457f-9330-59b7c0edbe98","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:07:34.559488Z","iopub.execute_input":"2025-07-08T19:07:34.559756Z","iopub.status.idle":"2025-07-08T19:09:01.718923Z","shell.execute_reply.started":"2025-07-08T19:07:34.559736Z","shell.execute_reply":"2025-07-08T19:09:01.718119Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"_uuid":"f3fcb54b-14c2-4f8d-b899-f53b56f1af94","_cell_guid":"19fb87e6-5061-4737-8bb7-1ac2339483ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-08T19:09:01.720730Z","iopub.execute_input":"2025-07-08T19:09:01.721551Z","iopub.status.idle":"2025-07-08T19:09:01.989803Z","shell.execute_reply.started":"2025-07-08T19:09:01.721503Z","shell.execute_reply":"2025-07-08T19:09:01.989255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=\"LEmZLocu5LCHOkUvVoOS\")\nproject = rf.workspace(\"ashwin-bhai-ki-help\").project(\"tactile_mapcrop_dataset\")\nversion = project.version(3)\ndataset = version.download(\"yolov8-obb\")","metadata":{"_uuid":"35255a8a-9448-4ac8-895b-c1738a376eb1","_cell_guid":"cf2da56a-3904-43a6-8a15-e508722121f8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:09:01.990712Z","iopub.execute_input":"2025-07-08T19:09:01.991073Z","iopub.status.idle":"2025-07-08T19:09:04.558271Z","shell.execute_reply.started":"2025-07-08T19:09:01.991054Z","shell.execute_reply":"2025-07-08T19:09:04.557669Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\nimport os","metadata":{"_uuid":"74f92e90-5155-4e42-845c-124f02d7fb03","_cell_guid":"5d2c0301-65a9-4670-b771-5cd48157578e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:09:04.559539Z","iopub.execute_input":"2025-07-08T19:09:04.559722Z","iopub.status.idle":"2025-07-08T19:09:04.562982Z","shell.execute_reply.started":"2025-07-08T19:09:04.559707Z","shell.execute_reply":"2025-07-08T19:09:04.562318Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the path to your data.yaml file\ndata_yaml_path = os.path.join(dataset.location, '/kaggle/working/TacTile_mapCrop_Dataset-3/data.yaml')\n\n# Check if data.yaml exists\nif not os.path.exists(data_yaml_path):\n    print(f\"Error: data.yaml not found at {data_yaml_path}\")\nelse:\n    # Read the data.yaml file\n    with open(data_yaml_path, 'r') as file:\n        data = yaml.safe_load(file)\n\n    # Update the 'path' key to reflect the current dataset location\n    # This is often necessary in Kaggle as the initial path might be absolute or incorrect.\n    data['path'] = dataset.location\n\n    # Ensure train, val, test paths are relative to the 'path'\n    # Roboflow usually exports them correctly, but it's good to confirm.\n    # Adjust these if your folder structure is different within the downloaded dataset.\n    data['train'] = 'train/images'\n    data['val'] = 'valid/images'\n    # If you have a test set and want to use it, uncomment the line below:\n    # data['test'] = 'test/images'\n\n    # Write the updated data.yaml back to the file\n    with open(data_yaml_path, 'w') as file:\n        yaml.dump(data, file, sort_keys=False)\n\n    print(f\"Updated data.yaml content:\\n{data}\")\n\n# You can also list the contents of your downloaded dataset directory to verify\nprint(\"\\nContents of downloaded dataset directory:\")\n!ls -R {dataset.location}","metadata":{"_uuid":"65312c06-254c-49b7-b000-5c98297b281a","_cell_guid":"e7b28d08-c23b-4b79-8d73-cd35072c5f4e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:09:04.563644Z","iopub.execute_input":"2025-07-08T19:09:04.563840Z","iopub.status.idle":"2025-07-08T19:09:04.705992Z","shell.execute_reply.started":"2025-07-08T19:09:04.563825Z","shell.execute_reply":"2025-07-08T19:09:04.705051Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a pre-trained YOLOv8 OBB model.\n# 'yolov8n-obb.pt' is the nano version, good for quick experiments.\n# You can choose 'yolov8s-obb.pt', 'yolov8m-obb.pt', 'yolov8l-obb.pt', or 'yolov8x-obb.pt'\n# depending on your desired trade-off between speed and accuracy, and available GPU memory.\nmodel = YOLO('yolov8n-obb.pt')\n\nprint(\"YOLOv8 OBB model loaded successfully.\")","metadata":{"_uuid":"7adb5692-92cd-40c9-8e91-1adb82f3e357","_cell_guid":"5d524379-4df4-4332-8dc8-2e98bcf4ca2b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:11:28.352884Z","iopub.execute_input":"2025-07-08T19:11:28.353802Z","iopub.status.idle":"2025-07-08T19:11:33.303051Z","shell.execute_reply.started":"2025-07-08T19:11:28.353777Z","shell.execute_reply":"2025-07-08T19:11:33.301846Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming you have already executed the following:\n# !pip install ultralytics\n# !pip install supervision\n# from roboflow import Roboflow\n# rf = Roboflow(api_key=\"YOUR_ROBOFLOW_API_KEY\") # Replace with your actual API key\n# project = rf.workspace(\"ashwin-bhai-ki-help\").project(\"tactile_mapcrop_dataset\")\n# version = project.version(3)\n# dataset = version.download(\"yolov8-obb\")\n# And the data.yaml verification/update part...\n# from ultralytics import YOLO\n# model = YOLO('yolov8n-obb.pt')\n\n\n# --- Define training parameters ---\nepochs = 300       # Set a sufficiently high number of epochs. Early stopping will halt it.\nimgsz = 640        # Image size for training (square images are common)\nbatch_size = 16    # Batch size (adjust based on your GPU memory; smaller if OOM)\nproject_name = 'YOLOv8_OBB_Training' # Name for your training project\n# It's good practice to change the run name when you change parameters\nrun_name = 'tactile_map_obb_run_with_early_stopping' \n\n# --- Early Stopping Parameter ---\n# Training will stop if the validation metric (mAP50-95 for OBB) does not improve\n# for 'patience_epochs' consecutive epochs.\npatience_epochs = 50 # Example: Stop if no improvement for 50 consecutive epochs\n\nprint(f\"Starting training with data from: {data_yaml_path}\")\nprint(f\"Early stopping patience set to: {patience_epochs} epochs\")\n\n# --- Train the model with early stopping ---\nresults = model.train(\n    data=data_yaml_path,\n    epochs=epochs,\n    imgsz=imgsz,\n    batch=batch_size,\n    project=project_name,\n    name=run_name,\n    patience=patience_epochs, # <--- THIS IS WHERE EARLY STOPPING IS APPLIED\n    # You can add other parameters here, e.g.,\n    # lr0=0.01, # Initial learning rate\n    # optimizer='AdamW', # Choose optimizer\n    # device=0 # Use GPU 0, or 'cpu' for CPU training (much slower)\n)\n\nprint(\"\\nTraining complete!\")\n\n# --- Post-Training Evaluation and Prediction (remains largely the same) ---\nimport os\nimport cv2\nimport supervision as sv\nimport random # For picking a random test image\nimport matplotlib.pyplot as plt # Make sure matplotlib is imported if you want to display images\n\n# Path to your best trained model weights\n# The path will be something like: /kaggle/working/YOLOv8_OBB_Training/tactile_map_obb_run_with_early_stopping/weights/best.pt\nbest_model_path = os.path.join('/kaggle/working', project_name, run_name, 'weights', 'best.pt')\n\nif os.path.exists(best_model_path):\n    print(f\"\\nLoading best model from: {best_model_path}\")\n    model = YOLO(best_model_path)\n\n    # Validate the model on the validation set\n    print(\"\\nRunning validation on the trained model:\")\n    metrics = model.val(data=data_yaml_path)\n\n    print(f\"mAP50-95(B): {metrics.box.map}\")\n    print(f\"mAP50(B): {metrics.box.map50}\")\n    print(f\"mAP(B) per class: {metrics.box.maps}\")\n\n    # --- Make predictions on a sample image ---\n    print(\"\\nMaking predictions on a sample test image:\")\n    test_images_dir = os.path.join(dataset.location, 'test', 'images')\n\n    if os.path.exists(test_images_dir) and os.listdir(test_images_dir):\n        random_image_name = random.choice(os.listdir(test_images_dir))\n        image_to_predict_path = os.path.join(test_images_dir, random_image_name)\n\n        print(f\"Predicting on: {image_to_predict_path}\")\n\n        # Perform inference\n        inference_results = model(image_to_predict_path)\n\n        # Get the first result object (assuming batch size 1 for simplicity here)\n        result = inference_results[0]\n\n        # Extract OBB detections using supervision\n        detections = sv.Detections.from_ultralytics(result)\n\n        # Annotate the image\n        image = cv2.imread(image_to_predict_path)\n        if image is None:\n            print(f\"Error: Could not read image at {image_to_predict_path}\")\n        else:\n            oriented_box_annotator = sv.OrientedBoxAnnotator()\n            annotated_frame = oriented_box_annotator.annotate(\n                scene=image.copy(),\n                detections=detections\n            )\n\n            # Display the annotated image\n            plt.figure(figsize=(10, 10))\n            plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n            plt.axis('off')\n            plt.title(\"Predicted OBBs\")\n            plt.show()\n\n            # Print raw OBB results\n            print(\"Raw OBB prediction results:\")\n            print(result.obb)\n            print(\"Class names:\", result.names) # Map class IDs to names\n\n    else:\n        print(\"No test images found or directory is empty. Cannot perform sample prediction.\")\nelse:\n    print(f\"Error: Best model not found at {best_model_path}. Training might not have completed successfully.\")","metadata":{"_uuid":"550bbebf-14d9-40b0-87b2-c1d6f437673f","_cell_guid":"e43d8688-e93c-49c3-808f-7bf34629bbb8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:11:43.572250Z","iopub.execute_input":"2025-07-08T19:11:43.572665Z","iopub.status.idle":"2025-07-08T19:15:20.156582Z","shell.execute_reply.started":"2025-07-08T19:11:43.572641Z","shell.execute_reply":"2025-07-08T19:15:20.155658Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\n\n# Assuming your previous training saved the model in this path\nproject_name = 'YOLOv8_OBB_Training'\nrun_name = 'tactile_map_obb_run_with_early_stopping' # Or whatever your last run name was\nbest_model_path = os.path.join('/kaggle/working', project_name, run_name, 'weights', 'best.pt')\n\nmodel = YOLO(best_model_path)\nprint(f\"Loaded model from: {best_model_path}\")","metadata":{"_uuid":"4175c787-b464-4f96-86b5-5689e3de037f","_cell_guid":"d3af72e5-ef60-4bc0-a970-6b94aaa35f9a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:16:39.095931Z","iopub.execute_input":"2025-07-08T19:16:39.096310Z","iopub.status.idle":"2025-07-08T19:16:39.140844Z","shell.execute_reply.started":"2025-07-08T19:16:39.096279Z","shell.execute_reply":"2025-07-08T19:16:39.140199Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Export to TFLite (float32)\ntflite_model_path = model.export(format='tflite', imgsz=640) # imgsz should match your training size\nprint(f\"Model exported to: {tflite_model_path}\")\n\n# Optional: Export with INT8 quantization (reduces size significantly, may affect accuracy)\n# This requires a representative dataset for calibration.\n# If your dataset has a 'test' split, you can use it for calibration.\n# Note: Quantization can be tricky with OBB and might require more specific steps or checking Ultralytics/TensorFlow Lite documentation for full support.\n# If the simple 'tflite' export works, start with that.\n# You would need to provide a DataLoader or representative dataset for `data` argument here.\n# quantized_tflite_model_path = model.export(format='tflite', imgsz=640, int8=True, data=data_yaml_path)\n# print(f\"Quantized model exported to: {quantized_tflite_model_path}\")\n\n# After running this, download the .tflite file from your Kaggle output.\n# It will be in the same directory as your best.pt (e.g., /kaggle/working/YOLOv8_OBB_Training/tactile_map_obb_run_with_early_stopping/)\n# The file name will be something like 'best_float32.tflite' or 'best_int8.tflite'.","metadata":{"_uuid":"6fa2ee68-6929-401a-9790-e9ce9a8eb29e","_cell_guid":"00d93b89-e3a8-496c-937c-c5f434f4a251","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:17:02.942773Z","iopub.execute_input":"2025-07-08T19:17:02.943417Z","iopub.status.idle":"2025-07-08T19:17:59.005851Z","shell.execute_reply.started":"2025-07-08T19:17:02.943395Z","shell.execute_reply":"2025-07-08T19:17:59.005204Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\n\n# Define the name for your zip file\nzip_filename = \"kaggle_working_output.zip\"\n\n# Change to the working directory. This ensures the zip command is run\n# from the correct location, making it easier to manage paths within the zip.\nos.chdir('/kaggle/working/')\n\nprint(f\"Current directory: {os.getcwd()}\")\nprint(f\"Zipping contents of /kaggle/working/ into {zip_filename}...\")\n\n# Use the 'zip' command to compress the entire /kaggle/working/ directory.\n# `!`: Executes a shell command\n# `zip`: The command-line utility for zipping files\n# `-r`: Recursive; includes subdirectories and their contents\n# `.`: Zips the current directory (which is /kaggle/working/ because of os.chdir)\n# `*`: (Optional, but often useful) Zips all files and directories *directly* within /kaggle/working/\n#      If you omit `*`, it will include the /kaggle/working/ parent folder inside the zip.\n#      If you include `*`, it will only zip the *contents* of /kaggle/working/.\n#      I've used `*` here as it's common to want the contents directly.\n!zip -r {zip_filename} ./*\n\nprint(f\"\\nZip file '{zip_filename}' created.\")\n\n# Generate a clickable download link for the created zip file.\n# The FileLink assumes the file is in the current working directory.\nprint(\"Click the link below to download your zipped folder:\")\nFileLink(f'./{zip_filename}')","metadata":{"_uuid":"5f5244e5-56b9-48f9-a4be-03a3bf825241","_cell_guid":"04f21e58-8290-465f-841a-a04bd55c7536","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-08T19:20:53.828187Z","iopub.execute_input":"2025-07-08T19:20:53.828958Z","iopub.status.idle":"2025-07-08T19:20:58.087459Z","shell.execute_reply.started":"2025-07-08T19:20:53.828933Z","shell.execute_reply":"2025-07-08T19:20:58.086699Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}